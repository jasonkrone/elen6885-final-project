\begin{abstract}
Transfer learning has been extremely successful in the computer vision domain.
This exemplified by the fact that most state-of-the-art deep classification,
detection, and segmentation networks are first pre-trained on the imagenet dataset
and then fine tuned on the evaluation dataset. However, in the Reinforcement Learning domain,
transfer learning has not exhibited the same level of success. Policies learned by agents
are not easily transferable to new similar tasks. Moreover, most research in this area
has been confined to discrete action spaces. In this work we propose a novel transfer
learning method for continuous control tasks. We benchmark our proposed method
against existing policy transfer methods, which until now have only been applied to
to discrete action spaces.
\end{abstract}
